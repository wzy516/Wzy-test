{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d97711b-ee61-42e6-bd70-c47b7eea3ffb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "\n",
    "# 设置中文字体（推荐使用系统内置字体，如 SimHei、Microsoft YaHei）\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 设置全局字体\n",
    "plt.rcParams['axes.unicode_minus'] = False    # 解决负号显示异常问题\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=10, min_samples_split=5):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.feature_indices = None\n",
    "        self.tree = None\n",
    "\n",
    "    def _gini(self, y):\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "        prob = counts / len(y)\n",
    "        return 1 - np.sum(prob ** 2)\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        best_gini = float('inf')\n",
    "        best_feature, best_threshold = None, None\n",
    "\n",
    "        for feature in self.feature_indices:\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                left_idx = X[:, feature] <= threshold\n",
    "                if np.sum(left_idx) > 0 and np.sum(~left_idx) > 0:\n",
    "                    gini = (len(y[left_idx]) * self._gini(y[left_idx]) +\n",
    "                            len(y[~left_idx]) * self._gini(y[~left_idx])) / len(y)\n",
    "                    if gini < best_gini:\n",
    "                        best_gini = gini\n",
    "                        best_feature = feature\n",
    "                        best_threshold = threshold\n",
    "        return best_feature, best_threshold, best_gini\n",
    "\n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        if (depth >= self.max_depth or\n",
    "                len(y) < self.min_samples_split or\n",
    "                len(np.unique(y)) == 1):\n",
    "            return {'class': np.argmax(np.bincount(y))}\n",
    "\n",
    "        feature, threshold, gini = self._best_split(X, y)\n",
    "        if feature is None:\n",
    "            return {'class': np.argmax(np.bincount(y))}\n",
    "\n",
    "        left_idx = X[:, feature] <= threshold\n",
    "        return {\n",
    "            'feature': feature,\n",
    "            'threshold': threshold,\n",
    "            'gini': gini,\n",
    "            'left': self._build_tree(X[left_idx], y[left_idx], depth + 1),\n",
    "            'right': self._build_tree(X[~left_idx], y[~left_idx], depth + 1)\n",
    "        }\n",
    "\n",
    "    def fit(self, X, y, n_features=None):\n",
    "        self.feature_indices = np.random.choice(X.shape[1],\n",
    "                                                n_features or int(np.sqrt(X.shape[1])), replace=False)\n",
    "        self.tree = self._build_tree(X, y)\n",
    "\n",
    "    def _predict_single(self, x, node):\n",
    "        if 'class' in node:\n",
    "            return node['class']\n",
    "        if x[node['feature']] <= node['threshold']:\n",
    "            return self._predict_single(x, node['left'])\n",
    "        return self._predict_single(x, node['right'])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_single(x, self.tree) for x in X])\n",
    "\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=100, max_depth=10, min_samples_split=5):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.trees = []\n",
    "        self.feature_importances = None\n",
    "\n",
    "    def _bootstrap_sample(self, X, y):\n",
    "        n_samples = X.shape[0]\n",
    "        indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "        return X[indices], y[indices]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.feature_importances = np.zeros(X.shape[1])\n",
    "        for _ in range(self.n_estimators):\n",
    "            X_sample, y_sample = self._bootstrap_sample(X, y)\n",
    "            tree = DecisionTree(max_depth=self.max_depth,\n",
    "                                min_samples_split=self.min_samples_split)\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            self.trees.append(tree)\n",
    "            self._update_feature_importance(tree.tree)\n",
    "\n",
    "        self.feature_importances /= np.sum(self.feature_importances)\n",
    "\n",
    "    def _update_feature_importance(self, node):\n",
    "        if 'feature' in node:\n",
    "            self.feature_importances[node['feature']] += 1 - node['gini']\n",
    "            self._update_feature_importance(node['left'])\n",
    "            self._update_feature_importance(node['right'])\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return np.apply_along_axis(lambda x: np.argmax(np.bincount(x)),\n",
    "                                   axis=0, arr=predictions)\n",
    "\n",
    "\n",
    "# 数据加载与预处理\n",
    "#iris = load_iris()\n",
    "#X, y = iris.data, iris.target\n",
    "columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "df = pd.read_csv(r'D:\\下载\\iris\\iris.data', header=None, names=columns)\n",
    "\n",
    "# 数据清洗验证\n",
    "print(f\"原始数据量: {len(df)}条\")\n",
    "print(\"缺失值统计:\", df.isnull().sum())\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f\"去重后数据量: {len(df)}条\")\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "X = df.iloc[:, :-1].values\n",
    "y = le.fit_transform(df.iloc[:, -1])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 模型训练\n",
    "rf = RandomForest(n_estimators=100, max_depth=5)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 模型评估n\n",
    "y_pred = rf.predict(X_test)\n",
    "print(f\"准确率: {accuracy_score(y_test, y_pred):.2%}\")\n",
    "\n",
    "# 混淆矩阵可视化\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('预测标签')\n",
    "plt.ylabel('真实标签')\n",
    "plt.title('混淆矩阵')\n",
    "plt.show()\n",
    "\n",
    "# 特征重要性可视化\n",
    "features = columns[:-1]\n",
    "importances = rf.feature_importances\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=importances[indices], y=np.array(features)[indices],hue=np.array(features)[indices], palette='viridis', legend=False)\n",
    "plt.title('特征重要性评估')\n",
    "plt.xlabel('重要性得分')\n",
    "plt.ylabel('特征名称')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702a1743-b873-406e-b6ba-4d9adc4da1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python pytorch",
   "language": "python",
   "name": "wzy-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
